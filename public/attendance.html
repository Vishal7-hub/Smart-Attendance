<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Smart Attendance | AI Surveillance</title>
  <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet"/>
  <script defer src="https://www.gstatic.com/firebasejs/9.22.1/firebase-app-compat.js"></script>
  <script defer src="https://www.gstatic.com/firebasejs/9.22.1/firebase-firestore-compat.js"></script>
  <script defer src="firebase-config.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <style>
    body {
      background: #0a0f1a;
      color: white;
      font-family: 'Segoe UI', sans-serif;
    }
    .btn-glow {
      background: linear-gradient(to right, #00ffab, #05c2ff);
      color: #0e1621;
      font-weight: bold;
      padding: 0.75rem 1.5rem;
      border-radius: 9999px;
      transition: transform 0.2s, box-shadow 0.3s;
    }
    .btn-glow:hover {
      transform: scale(1.05);
      box-shadow: 0 0 20px #00ffab;
    }
    #video {
      display: none;
      width: 80%;
      max-width: 600px;
      border: 4px solid #0ff;
      border-radius: 10px;
      margin-top: 1rem;
    }
    #log {
      margin-top: 1rem;
      color: #00ffcc;
    }
  </style>
</head>
<body class="min-h-screen flex flex-col items-center justify-center px-4 py-10">

  <!-- âœ… Back Button -->
  <a href="index.html" class="fixed top-4 right-6 btn-glow text-sm px-4 py-2">â¬… Back to Home</a>

  <!-- âœ… Intro Section -->
  <section id="intro" class="text-center max-w-2xl">
    <h1 class="text-4xl font-bold mb-4 text-[#05c2ff]">Smart Attendance System</h1>
    <p class="mb-6 text-gray-300">
      Our Smart Attendance feature uses facial recognition for accurate and efficient attendance tracking in real-time. Say goodbye to proxies and manual logs!
    </p>
    <ul class="text-left list-disc list-inside mb-6 text-gray-400">
      <li>ðŸ”’ Secure facial recognition</li>
      <li>ðŸ§  AI-powered real-time detection</li>
      <li>ðŸ•’ Timestamped attendance logs</li>
    </ul>
    <button id="startBtn" class="btn-glow">ðŸ“· Take Attendance</button>
  </section>

  <!-- âœ… Camera & Attendance Section -->
  <video id="video" autoplay muted playsinline></video>
  <div id="log" class="text-center mt-4"></div>

  <script>
    const startBtn = document.getElementById("startBtn");
    const video = document.getElementById("video");
    const log = document.getElementById("log");
    let faceMatcher, detectionInterval;

    async function loadModels() {
      const MODEL_URL = 'models';
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(`${MODEL_URL}/tiny_face_detector`),
        faceapi.nets.faceLandmark68Net.loadFromUri(`${MODEL_URL}/face_landmark_68`),
        faceapi.nets.faceRecognitionNet.loadFromUri(`${MODEL_URL}/face_recognition`),
        faceapi.nets.ssdMobilenetv1.loadFromUri(`${MODEL_URL}/ssd_mobilenetv1`)
      ]);
    }

    async function loadLabeledImages() {
      const labels = [ 'Sourav', 'Debojyoti'];
      return Promise.all(
        labels.map(async label => {
          const descriptions = [];
          for (let i = 1; i <= 2; i++) {
            const img = await faceapi.fetchImage(`labeled_images/${label}/${i}.jpg`);
            const det = await faceapi
              .detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
              .withFaceLandmarks()
              .withFaceDescriptor();
            if (det) descriptions.push(det.descriptor);
          }
          return new faceapi.LabeledFaceDescriptors(label, descriptions);
        })
      );
    }

    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      video.style.display = 'block';
      log.innerText = "âœ… Camera started. Detecting...";
    }

    async function detectFace() {
      const result = await faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (result) {
        clearInterval(detectionInterval);
        const bestMatch = faceMatcher.findBestMatch(result.descriptor);
        const name = bestMatch.label;
        const time = new Date().toLocaleString();
        log.innerText = `âœ… ${name}'s attendance marked at ${time}`;

        const db = firebase.firestore();
        db.collection("attendance").add({ name, time });
      } else {
        log.innerText = "ðŸ”Ž No face detected.";
      }
    }

    startBtn.addEventListener('click', async () => {
      document.getElementById("intro").style.display = "none";
      await loadModels();
      const labeled = await loadLabeledImages();
      faceMatcher = new faceapi.FaceMatcher(labeled, 0.6);
      await startCamera();
      video.addEventListener('playing', () => {
        detectionInterval = setInterval(detectFace, 1000);
      });
    });
  </script>

</body>
</html>