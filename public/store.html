<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI for Attendance Tracking</title>
  <style>
    body {
      background: #0a0f1a;
      color: #fff;
      font-family: sans-serif;
      text-align: center;
      margin: 0;
      padding: 1rem;
    }

    video {
      width: 80%;
      max-width: 600px;
      border: 4px solid #0ff;
      border-radius: 8px;
      margin-top: 1rem;
    }

    #log {
      margin-top: 1rem;
      color: #0f0;
    }

    .back-button {
      position: fixed;
      top: 20px;
      right: 20px;
      background: linear-gradient(to right, #00ffe0, #00ccb3);
      color: black;
      padding: 10px 18px;
      border: none;
      border-radius: 30px;
      font-weight: bold;
      text-decoration: none;
      box-shadow: 0 4px 12px rgba(0, 255, 224, 0.3);
      transition: background 0.3s ease, transform 0.2s ease;
      z-index: 999;
    }

    .back-button:hover {
      background: linear-gradient(to right, #00ccb3, #00ffe0);
      transform: scale(1.05);
    }
  </style>
</head>
<body>

  <a href="index.html" class="back-button">⬅ Back to Home</a>

  <h1>AI for Attendance Tracking</h1>
  <video id="video" autoplay muted playsinline></video>
  <div id="log">Initializing…</div>

  <!-- Firebase + FaceAPI Scripts -->
  <script defer src="https://www.gstatic.com/firebasejs/9.22.1/firebase-app-compat.js"></script>
  <script defer src="https://www.gstatic.com/firebasejs/9.22.1/firebase-firestore-compat.js"></script>
  <script defer src="firebase-config.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <script>
    const video = document.getElementById('video');
    const log = document.getElementById('log');
    let detectionLoop;

    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        log.innerText = "✅ Camera started. Looking for a face…";
      } catch (err) {
        log.innerText = "❌ Camera error: " + err.message;
      }
    }

    async function loadModels() {
      log.innerText = "⏳ Loading face-api models…";
      const MODEL_URL = 'models';
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(`${MODEL_URL}/tiny_face_detector`),
        faceapi.nets.faceLandmark68Net.loadFromUri(`${MODEL_URL}/face_landmark_68`),
        faceapi.nets.faceRecognitionNet.loadFromUri(`${MODEL_URL}/face_recognition`)
      ]);
      log.innerText = "✅ Models loaded.";
    }

    async function detectFace() {
      const detection = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions());
      console.log('Detection:', detection);
      if (detection) {
        clearInterval(detectionLoop);
        const timestamp = new Date().toLocaleString();
        log.innerText = `✅ Face detected! Marked at ${timestamp}`;

        const db = firebase.firestore();
        db.collection("attendance").add({ time: timestamp })
          .then(() => console.log('✅ Attendance saved'))
          .catch(err => console.error('❌ Save error', err));
      } else {
        log.innerText = "🔎 No face yet…";
      }
    }

    window.addEventListener('load', async () => {
      await loadModels();
      await startCamera();

      // Wait for video to actually play
      video.addEventListener('playing', () => {
        detectionLoop = setInterval(detectFace, 1000);
      });
    });
  </script>
</body>
</html>










<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI Surveillance</title>
  <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r121/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/vanta@latest/dist/vanta.net.min.js"></script>
  <style>
    #vanta-bg {
      height: 100vh;
      width: 100%;
      position: absolute;
      top: 0;
      left: 0;
      z-index: -1;
    }
  </style>
</head>
<body class="bg-gray-900 text-white">
  <div id="vanta-bg"></div>

  <!-- Header -->
  <header class="flex items-center justify-between px-6 py-4 bg-opacity-90 bg-gray-800 shadow-md">
    <div class="flex items-center space-x-3">
      <img src="https://img.icons8.com/external-flat-icons-inmotus-design/64/ffffff/external-cctv-security-flat-icons-inmotus-design.png" alt="Logo" class="w-8 h-8" />
      <h1 class="text-2xl font-bold text-white">AI Surveillance</h1>
    </div>

    <div class="flex space-x-3">
      <a href="admin.html" class="bg-yellow-400 hover:bg-yellow-300 text-black font-bold py-2 px-4 rounded-full">
        Admin
      </a>
      <a href="enquiry.html" class="bg-gradient-to-r from-green-400 to-blue-500 text-black font-bold py-2 px-4 rounded-full">
        Request a Demo
      </a>
    </div>
  </header>

  <!-- Main Section -->
  <main class="flex flex-col items-center justify-center text-center mt-24 px-4">
    <h2 class="text-4xl md:text-5xl font-bold mb-4">Turn Any CCTV into a Smart System</h2>
    <p class="text-lg md:text-xl mb-6">AI for Attendance Tracking, Gesture Control, and Traffic Monitoring</p>
    <a href="enquiry.html" class="bg-cyan-400 hover:bg-cyan-300 text-black font-semibold py-2 px-6 rounded-full text-lg">Get Started</a>

    <div class="mt-16 grid grid-cols-1 md:grid-cols-3 gap-8 max-w-5xl">
      <a href="attendance.html" class="bg-gray-800 hover:bg-gray-700 p-6 rounded-lg shadow-md">
        <h3 class="text-xl font-bold mb-2">🎓 AI Attendance</h3>
        <p>Face recognition via CCTV. Automated attendance linked with ERP or Google Sheets.</p>
      </a>

      <a href="gesture.html" class="bg-gray-800 hover:bg-gray-700 p-6 rounded-lg shadow-md">
        <h3 class="text-xl font-bold mb-2">🤖 Gesture Control</h3>
        <p>Control fans/lights/projectors using hand gestures. Save energy, add automation.</p>
      </a>

      <a href="traffic.html" class="bg-gray-800 hover:bg-gray-700 p-6 rounded-lg shadow-md">
        <h3 class="text-xl font-bold mb-2">🚦 Traffic Detection</h3>
        <p>Detect speed violations, auto-alert traffic police, integrate ANPR (number plate recognition).</p>
      </a>
    </div>
  </main>

  <!-- Footer -->
  <footer class="text-center p-4 text-sm text-gray-400 mt-16">
    © 2025 AI Surveillance | All Rights Reserved
  </footer>

  <!-- Vanta Background -->
  <script>
    VANTA.NET({
      el: "#vanta-bg",
      mouseControls: true,
      touchControls: true,
      minHeight: 200.00,
      minWidth: 200.00,
      scale: 1.00,
      scaleMobile: 1.00,
      color: 0x00ffff,
      backgroundColor: 0x0d1117
    });
  </script>
</body>
</html>


https://img.icons8.com/external-flat-icons-inmotus-design/64/ffffff/external-cctv-security-flat-icons-inmotus-design.png











<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Request a Demo | AI Surveillance</title>
  <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
  <link href="https://unpkg.com/aos@2.3.4/dist/aos.css" rel="stylesheet">
  <style>
    html, body {
      margin: 0;
      padding: 0;
      height: 100%;
      font-family: 'Segoe UI', sans-serif;
    }

    body {
      background: linear-gradient(to right, #0f2027, #203a43, #2c5364);
      color: #d1d5db;
      min-height: 100vh;
    }

    .neon-btn {
      background: linear-gradient(to right, #00ffab, #05c2ff);
      color: #0e1621;
      font-weight: bold;
      padding: 0.75rem 1.5rem;
      border-radius: 9999px;
      transition: transform 0.2s, box-shadow 0.3s;
    }

    .neon-btn:hover {
      transform: scale(1.05);
      box-shadow: 0 0 20px #00ffab;
    }

    .input-box {
      background: #1a2634;
      border: 1px solid #2f3e50;
      color: #e2e8f0;
    }

    .input-box:focus {
      outline: none;
      border-color: #00ffab;
      box-shadow: 0 0 10px #05c2ff33;
    }
  </style>
</head>
<body>

  <header class="bg-[#101b2d] shadow-md sticky top-0 z-50">
    <div class="max-w-6xl mx-auto px-6 py-5 flex justify-between items-center">
      <h1 class="text-2xl font-bold text-[#05c2ff]">AI Surveillance</h1>
      <a href="index.html" class="neon-btn">Back to Home</a>
    </div>
  </header>

  <main class="max-w-xl mx-auto mt-16 bg-[#121e2e] shadow-lg rounded-lg p-8" data-aos="fade-up">
    <h2 class="text-3xl font-bold text-center text-[#00ffab] mb-6">Request a Demo</h2>

    <form id="demoForm" class="space-y-5">
      <input type="text" name="name" placeholder="Your Name" required class="w-full px-4 py-3 rounded-lg input-box" />
      <input type="text" name="institution" placeholder="Institution Type" required class="w-full px-4 py-3 rounded-lg input-box" />
      <input type="text" name="system" placeholder="Existing CCTV System?" required class="w-full px-4 py-3 rounded-lg input-box" />
      <textarea name="services" placeholder="Services Required (Attendance, Gesture, etc)" rows="4" class="w-full px-4 py-3 rounded-lg input-box"></textarea>

      <button type="submit" class="w-full neon-btn">Submit Request</button>
    </form>
  </main>

  <footer class="text-center p-6 mt-16 text-gray-400 text-sm" data-aos="fade-in">
    © 2025 AI Surveillance | All Rights Reserved
  </footer>

  <!-- Firebase SDK -->
  <script src="https://www.gstatic.com/firebasejs/10.4.0/firebase-app.js"></script>
  <script src="https://www.gstatic.com/firebasejs/10.4.0/firebase-firestore.js"></script>
  <script src="firebase-config.js"></script>

  <script>
    const form = document.getElementById('demoForm');
    form.addEventListener('submit', async (e) => {
      e.preventDefault();
      const db = firebase.firestore();
      await db.collection("demoRequests").add({
        name: form.name.value,
        institution: form.institution.value,
        system: form.system.value,
        services: form.services.value,
        createdAt: new Date()
      });
      alert("✅ Request submitted! We will contact you shortly.");
      form.reset();
    });
  </script>

  <!-- AOS Init -->
  <script src="https://unpkg.com/aos@2.3.4/dist/aos.js"></script>
  <script>AOS.init();</script>
</body>
</html>






<!-- latest ke pchle wala  -->


<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI Attendance</title>
  <style>
    body {
      margin: 0;
      padding: 1rem;
      font-family: sans-serif;
      background: #0a0f1a;
      color: white;
      text-align: center;
    }
    video {
      margin-top: 20px;
      width: 80%;
      max-width: 600px;
      border: 4px solid #0ff;
      border-radius: 8px;
    }
    #log {
      margin-top: 1rem;
      color: #0f0;
    }
    .back-button {
      position: fixed;
      top: 20px;
      right: 20px;
      background: linear-gradient(to right, #00ffe0, #00ccb3);
      color: black;
      padding: 10px 18px;
      border: none;
      border-radius: 30px;
      font-weight: bold;
      text-decoration: none;
      box-shadow: 0 4px 12px rgba(0, 255, 224, 0.3);
      transition: background 0.3s ease, transform 0.2s ease;
      z-index: 999;
    }
    .back-button:hover {
      background: linear-gradient(to right, #00ccb3, #00ffe0);
      transform: scale(1.05);
    }
  </style>
</head>
<body>

  <a class="back-button" href="index.html">⬅ Back to Home</a>

  <h1>AI Attendance</h1>
  <video id="video" autoplay muted playsinline></video>
  <div id="log">Loading models...</div>

  <!-- Firebase + face-api.js -->
  <script defer src="https://www.gstatic.com/firebasejs/9.22.1/firebase-app-compat.js"></script>
  <script defer src="https://www.gstatic.com/firebasejs/9.22.1/firebase-firestore-compat.js"></script>
  <script defer src="firebase-config.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <script>
    const video = document.getElementById("video");
    const log = document.getElementById("log");
    let faceMatcher, detectionInterval;

    async function loadModels() {
      const MODEL_URL = 'models';
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(`${MODEL_URL}/tiny_face_detector`),
        faceapi.nets.faceLandmark68Net.loadFromUri(`${MODEL_URL}/face_landmark_68`),
        faceapi.nets.faceRecognitionNet.loadFromUri(`${MODEL_URL}/face_recognition`),
        faceapi.nets.ssdMobilenetv1.loadFromUri(`${MODEL_URL}/ssd_mobilenetv1`) // ✅ Fix: load to prevent error
      ]);
      log.innerText = "✅ All models loaded.";
    }

    async function loadLabeledImages() {
      const labels = ['Vishal', 'Sourav','prashant','Debojyoti']; // ✅ Folder names = person names

      return Promise.all(
        labels.map(async label => {
          const descriptions = [];
          for (let i = 1; i <= 2; i++) {
            const img = await faceapi.fetchImage(`labeled_images/${label}/${i}.jpg`);
            const det = await faceapi
              .detectSingleFace(img, new faceapi.TinyFaceDetectorOptions()) // ✅ force TinyFaceDetector
              .withFaceLandmarks()
              .withFaceDescriptor();
            if (det) descriptions.push(det.descriptor);
          }
          return new faceapi.LabeledFaceDescriptors(label, descriptions);
        })
      );
    }

    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      log.innerText = "✅ Camera started. Detecting...";
    }

    async function detectFace() {
      const result = await faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()) // ✅ explicitly use tinyFaceDetector
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (result) {
        clearInterval(detectionInterval);
        const bestMatch = faceMatcher.findBestMatch(result.descriptor);
        const name = bestMatch.label;
        const time = new Date().toLocaleString();
        log.innerText = `✅ ${name}'s attendance marked at ${time}`;

        const db = firebase.firestore();
        db.collection("attendance").add({ name, time });
      } else {
        log.innerText = "🔎 No face detected.";
      }
    }

    window.onload = async () => {
      await loadModels();
      const labeledDescriptors = await loadLabeledImages();
      faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);
      await startCamera();
      video.addEventListener('playing', () => {
        detectionInterval = setInterval(detectFace, 1000);
      });
    };
  </script>

</body>
</html>









<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Smart Attendance | AI Surveillance</title>
  <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet"/>
  <script defer src="https://www.gstatic.com/firebasejs/9.22.1/firebase-app-compat.js"></script>
  <script defer src="https://www.gstatic.com/firebasejs/9.22.1/firebase-firestore-compat.js"></script>
  <script defer src="firebase-config.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <style>
    body {
      background: #0a0f1a;
      color: white;
      font-family: 'Segoe UI', sans-serif;
    }
    .btn-glow {
      background: linear-gradient(to right, #00ffab, #05c2ff);
      color: #0e1621;
      font-weight: bold;
      padding: 0.75rem 1.5rem;
      border-radius: 9999px;
      transition: transform 0.2s, box-shadow 0.3s;
    }
    .btn-glow:hover {
      transform: scale(1.05);
      box-shadow: 0 0 20px #00ffab;
    }
    #video {
      display: none;
      width: 80%;
      max-width: 600px;
      border: 4px solid #0ff;
      border-radius: 10px;
      margin-top: 1rem;
    }
    #log {
      margin-top: 1rem;
      color: #00ffcc;
    }
  </style>
</head>
<body class="min-h-screen flex flex-col items-center justify-center px-4 py-10">

  <!-- ✅ Back Button -->
  <a href="index.html" class="fixed top-4 right-6 btn-glow text-sm px-4 py-2">⬅ Back to Home</a>

  <!-- ✅ Intro Section -->
  <section id="intro" class="text-center max-w-2xl">
    <h1 class="text-4xl font-bold mb-4 text-[#05c2ff]">Smart Attendance System</h1>
    <p class="mb-6 text-gray-300">
      Our Smart Attendance feature uses facial recognition for accurate and efficient attendance tracking in real-time. Say goodbye to proxies and manual logs!
    </p>
    <ul class="text-left list-disc list-inside mb-6 text-gray-400">
      <li>🔒 Secure facial recognition</li>
      <li>🧠 AI-powered real-time detection</li>
      <li>🕒 Timestamped attendance logs</li>
    </ul>
    <button id="startBtn" class="btn-glow">📷 Take Attendance</button>
  </section>

  <!-- ✅ Camera & Attendance Section -->
  <video id="video" autoplay muted playsinline></video>
  <div id="log" class="text-center mt-4"></div>

  <script>
    const startBtn = document.getElementById("startBtn");
    const video = document.getElementById("video");
    const log = document.getElementById("log");
    let faceMatcher, detectionInterval;

    async function loadModels() {
      const MODEL_URL = 'models';
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(`${MODEL_URL}/tiny_face_detector`),
        faceapi.nets.faceLandmark68Net.loadFromUri(`${MODEL_URL}/face_landmark_68`),
        faceapi.nets.faceRecognitionNet.loadFromUri(`${MODEL_URL}/face_recognition`),
        faceapi.nets.ssdMobilenetv1.loadFromUri(`${MODEL_URL}/ssd_mobilenetv1`)
      ]);
    }

    async function loadLabeledImages() {
      const labels = ['Vishal', 'Sourav', 'Prashant', 'Debojyoti'];
      return Promise.all(
        labels.map(async label => {
          const descriptions = [];
          for (let i = 1; i <= 2; i++) {
            const img = await faceapi.fetchImage(`labeled_images/${label}/${i}.jpg`);
            const det = await faceapi
              .detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
              .withFaceLandmarks()
              .withFaceDescriptor();
            if (det) descriptions.push(det.descriptor);
          }
          return new faceapi.LabeledFaceDescriptors(label, descriptions);
        })
      );
    }

    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      video.style.display = 'block';
      log.innerText = "✅ Camera started. Detecting...";
    }

    async function detectFace() {
      const result = await faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (result) {
        clearInterval(detectionInterval);
        const bestMatch = faceMatcher.findBestMatch(result.descriptor);
        const name = bestMatch.label;
        const time = new Date().toLocaleString();
        log.innerText = `✅ ${name}'s attendance marked at ${time}`;

        const db = firebase.firestore();
        db.collection("attendance").add({ name, time });
      } else {
        log.innerText = "🔎 No face detected.";
      }
    }

    startBtn.addEventListener('click', async () => {
      document.getElementById("intro").style.display = "none";
      await loadModels();
      const labeled = await loadLabeledImages();
      faceMatcher = new faceapi.FaceMatcher(labeled, 0.6);
      await startCamera();
      video.addEventListener('playing', () => {
        detectionInterval = setInterval(detectFace, 1000);
      });
    });
  </script>

</body>
</html>



